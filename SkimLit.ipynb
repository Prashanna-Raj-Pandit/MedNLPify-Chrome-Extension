{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOczzcBlDDP/E6wQgVTFlsv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prashanna-Raj-Pandit/SkimLit-Chrome-Extension/blob/main/SkimLit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Skimlit\n",
        "The propose of this project is to built an NLP model to make reading medical abstract easier.\n",
        "\n",
        "The paper we are replicating (the source of dataset that we'll be using) is available here: https://arxiv.org/pdf/1710.06071\n"
      ],
      "metadata": {
        "id": "u33WPGjusDBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLzOrmHLtSSE",
        "outputId": "90b525a6-1e5d-4e43-bd78-bb18c6244b8b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the data\n",
        "PubMed 200k RCT:\n",
        "a Dataset for Sequential Sentence Classification in Medical Abstracts https://github.com/Franck-Dernoncourt/pubmed-rct"
      ],
      "metadata": {
        "id": "ASWsGkHftxGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n",
        "!ls pubmed-rct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWnmfOI0t4Pn",
        "outputId": "b666874d-4200-4abb-9884-cdc67cf43340"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 39 (delta 8), reused 5 (delta 5), pack-reused 25 (from 1)\u001b[K\n",
            "Receiving objects: 100% (39/39), 177.08 MiB | 13.23 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Updating files: 100% (13/13), done.\n",
            "PubMed_200k_RCT\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_20k_RCT\n",
            "PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1EdyKrxvr8c",
        "outputId": "175d8a6c-8496-4a24-c2b1-7de8e467a91f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir=\"/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\"\n",
        "import os\n",
        "filename=[data_dir+filename for filename in os.listdir(data_dir)]\n",
        "filename"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y77PgTxtt0qo",
        "outputId": "e5266d21-88ee-46b4-8999-0d66c055063a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
              " '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
              " '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess data\n",
        "def get_lines(filename):\n",
        "  with open(filename) as file:\n",
        "    return file.readlines()"
      ],
      "metadata": {
        "id": "JrwbsO5ixMrS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_lines=get_lines(filename[0])\n",
        "train_lines[:30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQ54OMl16Lmn",
        "outputId": "265eca73-0871-4576-f632-5734cdc3c7ea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24845963\\n',\n",
              " 'BACKGROUND\\tThis study analyzed liver function abnormalities in heart failure patients admitted with severe acute decompensated heart failure ( ADHF ) .\\n',\n",
              " 'RESULTS\\tA post hoc analysis was conducted with the use of data from the Evaluation Study of Congestive Heart Failure and Pulmonary Artery Catheterization Effectiveness ( ESCAPE ) .\\n',\n",
              " 'RESULTS\\tLiver function tests ( LFTs ) were measured at @ time points from baseline , at discharge , and up to @ months follow-up .\\n',\n",
              " 'RESULTS\\tSurvival analyses were used to assess the association between admission Model of End-Stage Liver Disease Excluding International Normalized Ratio ( MELD-XI ) scores and patient outcome.There was a high prevalence of abnormal baseline ( admission ) LFTs ( albumin @ % , aspartate transaminase @ % , alanine transaminase @ % , and total bilirubin @ % ) .\\n',\n",
              " \"RESULTS\\tThe percentage of patients with abnormal LFTs decreased significantly from baseline to @-months ' follow-up .\\n\",\n",
              " 'RESULTS\\tWhen mean hemodynamic profiles were compared in patients with abnormal versus normal LFTs , elevated total bilirubin was associated with a significantly lower cardiac index ( @ vs @ ; P < @ ) and higher central venous pressure ( @ vs @ ; P = @ ) .\\n',\n",
              " 'RESULTS\\tMultivariable analyses revealed that patients with elevated MELD-XI scores ( @ ) had a @-fold ( hazard ratio@ @ , @ % confidence interval @-@ @ ) increased risk of death , rehospitalization , or transplantation after adjusting for baseline LFTs , age , sex , race , body mass index , diabetes , and systolic blood pressure .\\n',\n",
              " 'CONCLUSIONS\\tAbnormal LFTs are common in the ADHF population and are a dynamic marker of an impaired hemodynamic state .\\n',\n",
              " 'CONCLUSIONS\\tElevated MELD-XI scores are associated with poor outcomes among patients admitted with ADHF .\\n',\n",
              " '\\n',\n",
              " '###24469619\\n',\n",
              " 'BACKGROUND\\tMinimally invasive endovascular aneurysm repair ( EVAR ) could be a surgical technique that improves outcome of patients with ruptured abdominal aortic aneurysm ( rAAA ) .\\n',\n",
              " 'BACKGROUND\\tThe aim of this study was to analyse the cost-effectiveness and cost-utility of EVAR compared with standard open repair ( OR ) in the treatment of rAAA , with costs per @-day and @-month survivor as outcome parameters .\\n',\n",
              " 'METHODS\\tResource use was determined from the Amsterdam Acute Aneurysm ( AJAX ) trial , a multicentre randomized trial comparing EVAR with OR in patients with rAAA .\\n',\n",
              " 'METHODS\\tThe analysis was performed from a provider perspective .\\n',\n",
              " 'METHODS\\tAll costs were calculated as if all patients had been treated in the same hospital ( Onze Lieve Vrouwe Gasthuis , teaching hospital ) .\\n',\n",
              " 'RESULTS\\tA total of @ patients were randomized .\\n',\n",
              " 'RESULTS\\tThe @-day mortality rate was @ per cent after EVAR and @ per cent for OR : absolute risk reduction ( ARR ) @ ( @ per cent confidence interval ( c.i. ) -@ to @ ) per cent .\\n',\n",
              " 'RESULTS\\tAt @months , the total mortality rate for EVAR was @ per cent , compared with @ per cent among those assigned to OR : ARR @ ( -@ to @ ) per cent .\\n',\n",
              " 'RESULTS\\tThe mean cost difference between EVAR and OR was @ ( @ per cent c.i. -@ to @,@ ) at @days and @,@ ( -@ to @,@ ) at @months .\\n',\n",
              " 'RESULTS\\tThe incremental cost-effectiveness ratio per prevented death was @,@ at @days and @,@ at @months .\\n',\n",
              " 'RESULTS\\tThere was no significant difference in quality of life between EVAR and OR .\\n',\n",
              " 'RESULTS\\tNor was EVAR superior regarding cost-utility .\\n',\n",
              " 'CONCLUSIONS\\tEVAR may be more effective for rAAA , but its increased costs mean that it is unaffordable based on current standards of societal willingness-to-pay for health gains .\\n',\n",
              " '\\n',\n",
              " '###25552432\\n',\n",
              " 'BACKGROUND\\tEvidence suggests that individuals with social anxiety demonstrate vigilance to social threat , whilst the peptide hormone oxytocin is widely accepted as supporting affiliative behaviour in humans .\\n',\n",
              " 'METHODS\\tThis study investigated whether oxytocin can affect attentional bias in social anxiety .\\n',\n",
              " 'METHODS\\tIn a double-blind , randomized , placebo-controlled , within-group study design , @ healthy and @ highly socially anxious ( HSA ) male volunteers ( within the HSA group , @ were diagnosed with generalized social anxiety disorder ) were administered @ IU of oxytocin or placebo to investigate attentional processing in social anxiety .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text_with_line_numbers(filename):\n",
        "  input_lines=get_lines(filename)\n",
        "  abstract_line=\"\"\n",
        "  abstract_samples=[]\n",
        "\n",
        "  for line in input_lines:\n",
        "    if line.startswith('###'):\n",
        "      abstract_id=line\n",
        "      abstract_line=\"\"\n",
        "\n",
        "    elif line.isspace():\n",
        "      abstract_line_split=abstract_line.splitlines()\n",
        "      for abstract_line_number,abstract_line in enumerate(abstract_line_split):\n",
        "        line_data={}\n",
        "        target_text_split=abstract_line.split(\"\\t\")\n",
        "        line_data[\"target\"]=target_text_split[0]\n",
        "        line_data[\"text\"]=target_text_split[1].lower()\n",
        "        line_data[\"line_number\"]=abstract_line_number\n",
        "        line_data[\"total_lines\"]=len(abstract_line_split)-1\n",
        "        abstract_samples.append(line_data)\n",
        "    else:\n",
        "      abstract_line+=line\n",
        "  return abstract_samples"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_Hn5bjUa6t3T"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples=preprocess_text_with_line_numbers(filename[2])\n",
        "test_samples=preprocess_text_with_line_numbers(filename[1])\n",
        "validation_sample=preprocess_text_with_line_numbers(filename[0])\n",
        "\n",
        "len(train_samples),len(test_samples),len(validation_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YV9mkUQrAIVC",
        "outputId": "0bed70f7-2fef-4749-998c-10808653ddad"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30212, 180040, 30135)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kYP-eq0mu4a",
        "outputId": "4e8f8ea7-6db0-4f76-ef5e-888be40f79c3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'target': 'BACKGROUND',\n",
              "  'text': 'ige sensitization to aspergillus fumigatus and a positive sputum fungal culture result are common in patients with refractory asthma .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 9},\n",
              " {'target': 'BACKGROUND',\n",
              "  'text': 'it is not clear whether these patients would benefit from antifungal treatment .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 9},\n",
              " {'target': 'OBJECTIVE',\n",
              "  'text': 'we sought to determine whether a @-month course of voriconazole improved asthma-related outcomes in patients with asthma who are ige sensitized to a fumigatus .',\n",
              "  'line_number': 2,\n",
              "  'total_lines': 9},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'asthmatic patients who were ige sensitized to a fumigatus with a history of at least @ severe exacerbations in the previous @ months were treated for @ months with @ mg of voriconazole twice daily , followed by observation for @ months , in a double-blind , placebo-controlled , randomized design .',\n",
              "  'line_number': 3,\n",
              "  'total_lines': 9},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'primary outcomes were improvement in quality of life at the end of the treatment period and a reduction in the number of severe exacerbations over the @ months of the study .',\n",
              "  'line_number': 4,\n",
              "  'total_lines': 9},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'sixty-five patients were randomized .',\n",
              "  'line_number': 5,\n",
              "  'total_lines': 9},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'fifty-nine patients started treatment ( @ receiving voriconazole and @ receiving placebo ) and were included in an intention-to-treat analysis .',\n",
              "  'line_number': 6,\n",
              "  'total_lines': 9},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'fifty-six patients took the full @ months of medication .',\n",
              "  'line_number': 7,\n",
              "  'total_lines': 9},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'between the voriconazole and placebo groups , there were no significant differences in the number of severe exacerbations ( @ vs @ per patient per year , respectively ; mean difference , @ ; @ % ci , @-@ @ ) , quality of life ( change in asthma quality of life questionnaire score , @ vs @ ; mean difference between groups , @ ; @ % ci , -@ to -@ ) , or any of our secondary outcome measures .',\n",
              "  'line_number': 8,\n",
              "  'total_lines': 9},\n",
              " {'target': 'CONCLUSIONS',\n",
              "  'text': 'we were unable to show a beneficial effect of @ months of treatment with voriconazole in patients with moderate-to-severe asthma who were ige sensitized to a fumigatus on either the rate of severe exacerbations , quality of life , or other markers of asthma control .',\n",
              "  'line_number': 9,\n",
              "  'total_lines': 9}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df=pd.DataFrame(train_samples)\n",
        "test_df=pd.DataFrame(test_samples)\n",
        "val_df=pd.DataFrame(validation_sample)\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "P18E3AfWnqPd",
        "outputId": "77d4be65-093f-44e4-fffc-847d472b1ee0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       target                                               text  line_number  \\\n",
              "0  BACKGROUND  ige sensitization to aspergillus fumigatus and...            0   \n",
              "1  BACKGROUND  it is not clear whether these patients would b...            1   \n",
              "2   OBJECTIVE  we sought to determine whether a @-month cours...            2   \n",
              "3     METHODS  asthmatic patients who were ige sensitized to ...            3   \n",
              "4     METHODS  primary outcomes were improvement in quality o...            4   \n",
              "\n",
              "   total_lines  \n",
              "0            9  \n",
              "1            9  \n",
              "2            9  \n",
              "3            9  \n",
              "4            9  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ccaaf91e-9012-4e1d-ad5a-5a8568997ec4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>ige sensitization to aspergillus fumigatus and...</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>it is not clear whether these patients would b...</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>we sought to determine whether a @-month cours...</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>asthmatic patients who were ige sensitized to ...</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>primary outcomes were improvement in quality o...</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ccaaf91e-9012-4e1d-ad5a-5a8568997ec4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ccaaf91e-9012-4e1d-ad5a-5a8568997ec4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ccaaf91e-9012-4e1d-ad5a-5a8568997ec4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a1dee645-aedc-4251-9889-c3fabf9fef64\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a1dee645-aedc-4251-9889-c3fabf9fef64')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a1dee645-aedc-4251-9889-c3fabf9fef64 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 30212,\n  \"fields\": [\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"OBJECTIVE\",\n          \"CONCLUSIONS\",\n          \"METHODS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29870,\n        \"samples\": [\n          \"a reduction in pigment was observed with both lasers during the study period .\",\n          \"ten paramedics with field experience were trained with an ultrasound machine in the performance of the fast scan .\",\n          \"we examined the impact of milk proteins and combined exercise training ( cet ) on bp , arterial function , and muscle strength ( one-repetition maximum ( @-rm ) ) .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"line_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 26,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          8,\n          13,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_lines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 3,\n        \"max\": 26,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          16,\n          20,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distribution of labels in the training data\n"
      ],
      "metadata": {
        "id": "xmk76CbZopGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "uG5Bts9epXsC",
        "outputId": "ce02b8d3-0173-44f8-9765-39d6dbd6ab42"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "METHODS        9964\n",
              "RESULTS        9841\n",
              "CONCLUSIONS    4582\n",
              "BACKGROUND     3449\n",
              "OBJECTIVE      2376\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>METHODS</th>\n",
              "      <td>9964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RESULTS</th>\n",
              "      <td>9841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CONCLUSIONS</th>\n",
              "      <td>4582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BACKGROUND</th>\n",
              "      <td>3449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OBJECTIVE</th>\n",
              "      <td>2376</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems like the abstract talks mostly about Methods and Results and less about Objective"
      ],
      "metadata": {
        "id": "vVB6zyL0qA-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.total_lines.plot.hist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "UTRXL-sopjbW",
        "outputId": "c395c1ee-36c4-4989-fe8f-8a50d3c33e03"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: ylabel='Frequency'>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this Histogram, it seems like most of the abstract has the length of 7-18"
      ],
      "metadata": {
        "id": "BVDtbmk7qOfM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting the abstract lines into list"
      ],
      "metadata": {
        "id": "hUgTmHn6py_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences=train_df.text.to_list()\n",
        "test_sentences=test_df.text.to_list()\n",
        "validation_sentences=val_df.text.to_list()\n",
        "validation_sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoPQdEprrLi_",
        "outputId": "77823039-1f9c-4dbb-a73c-09bb4d78331a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this study analyzed liver function abnormalities in heart failure patients admitted with severe acute decompensated heart failure ( adhf ) .',\n",
              " 'a post hoc analysis was conducted with the use of data from the evaluation study of congestive heart failure and pulmonary artery catheterization effectiveness ( escape ) .',\n",
              " 'liver function tests ( lfts ) were measured at @ time points from baseline , at discharge , and up to @ months follow-up .',\n",
              " 'survival analyses were used to assess the association between admission model of end-stage liver disease excluding international normalized ratio ( meld-xi ) scores and patient outcome.there was a high prevalence of abnormal baseline ( admission ) lfts ( albumin @ % , aspartate transaminase @ % , alanine transaminase @ % , and total bilirubin @ % ) .',\n",
              " \"the percentage of patients with abnormal lfts decreased significantly from baseline to @-months ' follow-up .\",\n",
              " 'when mean hemodynamic profiles were compared in patients with abnormal versus normal lfts , elevated total bilirubin was associated with a significantly lower cardiac index ( @ vs @ ; p < @ ) and higher central venous pressure ( @ vs @ ; p = @ ) .',\n",
              " 'multivariable analyses revealed that patients with elevated meld-xi scores ( @ ) had a @-fold ( hazard ratio@ @ , @ % confidence interval @-@ @ ) increased risk of death , rehospitalization , or transplantation after adjusting for baseline lfts , age , sex , race , body mass index , diabetes , and systolic blood pressure .',\n",
              " 'abnormal lfts are common in the adhf population and are a dynamic marker of an impaired hemodynamic state .',\n",
              " 'elevated meld-xi scores are associated with poor outcomes among patients admitted with adhf .',\n",
              " 'minimally invasive endovascular aneurysm repair ( evar ) could be a surgical technique that improves outcome of patients with ruptured abdominal aortic aneurysm ( raaa ) .']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make numeric labels\n",
        "Lets make one-hot and label encoded labels. TF CategoricalCrossentropy loss function likes to have one hot encoded labels"
      ],
      "metadata": {
        "id": "t48fEay-rVnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encode labels\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder=OneHotEncoder(sparse_output=False)\n",
        "train_labels_one_hot=one_hot_encoder.fit_transform(train_df.target.to_numpy().reshape(-1,1))\n",
        "test_labels_one_hot=one_hot_encoder.fit_transform(test_df.target.to_numpy().reshape(-1,1))\n",
        "validation_labels_one_hot=one_hot_encoder.fit_transform(val_df.target.to_numpy().reshape(-1,1))\n",
        "validation_labels_one_hot[:10],train_labels_one_hot[:10],test_labels_one_hot[:10]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gg7ANdmqsHHb",
        "outputId": "e94bd8ff-b923-4c9e-922d-5f0eaa817571"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0.]]),\n",
              " array([[1., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0.],\n",
              "        [0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 1., 0., 0., 0.]]),\n",
              " array([[0., 0., 0., 1., 0.],\n",
              "        [0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# label encode labels"
      ],
      "metadata": {
        "id": "dJnlajMOtIie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract target columns and encode into integers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder=LabelEncoder()\n",
        "train_labels=label_encoder.fit_transform(train_df.target.to_numpy())\n",
        "test_labels=label_encoder.fit_transform(test_df.target.to_numpy())\n",
        "validation_labels=label_encoder.fit_transform(val_df.target.to_numpy())\n",
        "train_labels[:10],test_labels[:10],validation_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_4zhDkMGFNT",
        "outputId": "d758c7ec-47bc-4e4d-dd31-3d86a34c8e10"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 0, 3, 2, 2, 4, 4, 4, 4, 1]),\n",
              " array([3, 2, 2, 2, 2, 2, 4, 4, 4, 4]),\n",
              " array([0, 4, 4, 4, 4, 4, 4, 1, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the names and number of classes from LabelEncoder instance\n",
        "num_classes=len(label_encoder.classes_)\n",
        "class_names=label_encoder.classes_\n",
        "num_classes,class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyLu9AtfHHuR",
        "outputId": "9c664da8-3040-46bc-9c71-458bd9e68cc8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,\n",
              " array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YVOsPowIhE3",
        "outputId": "7497b8bd-c2dc-4c77-e907-5280282e1112"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 3, ..., 4, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 0: Baseline\n",
        "TF-IDF Multinomial Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "vvCxq5dygr_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "model_0=Pipeline([(\"tf-idf\",TfidfVectorizer()),\n",
        "                  (\"clf\",MultinomialNB()),\n",
        "                  ])\n",
        "# Fit the pipeline\n",
        "model_0.fit(train_sentences,train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "cyKIVzWehnW1",
        "outputId": "53e3381f-7e85-45b1-83c6-f477f575d9d8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tf-idf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tf-idf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tf-idf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate baseline model\n",
        "model_0.score(X=validation_sentences,y=validation_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xl-sCNfJjt3R",
        "outputId": "0368005c-19fb-4a41-9cf5-58c28bb02818"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6755931640949062"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make prediction\n",
        "baseline_preds=model_0.predict(validation_sentences)\n",
        "baseline_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aT-joQvkOpJ",
        "outputId": "387631cb-2798-40bd-ed59-7b894f598f3e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, 4, 4, 4, 4, 1, 4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCqCv6gYlhce",
        "outputId": "a4b7e7ba-e85a-465e-c351-53b28f944ac3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 4, 4, 4, 4, 4, 4, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the helper function\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/refs/heads/main/extras/helper_functions.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43fzo2gClqtA",
        "outputId": "7bad7d9e-b390-4981-ed66-44c454669cc8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-27 04:21:02--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/refs/heads/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: helper_functions.py\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-05-27 04:21:02 (95.5 MB/s) - helper_functions.py saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import calculate_results\n"
      ],
      "metadata": {
        "id": "UCYQIj29nL-U"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate baseline results\n",
        "baseline_results=calculate_results(y_true=validation_labels,y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YicBWnhPnUHJ",
        "outputId": "e9507cda-00d7-428f-df35-93e4b642cd4a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 67.55931640949062,\n",
              " 'precision': 0.6707354792180861,\n",
              " 'recall': 0.6755931640949062,\n",
              " 'f1': 0.6337858496380698}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 1: simple Dense Model"
      ],
      "metadata": {
        "id": "FXIMkGAfnhWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create tensorboard callback\n",
        "from helper_functions import create_tensorboard_callback\n",
        "SAVE_DIR=\"model_logs\"\n"
      ],
      "metadata": {
        "id": "FabXisW3pXTU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Lets create a text vectorization and embedding layers. The vectorization layer convert the text into numbers and the embedding layer will capture the relationship between those numbers"
      ],
      "metadata": {
        "id": "Me4DgRQYu9zq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7wMUKidsI40",
        "outputId": "1680c8fd-a5f4-4ab1-b838-9c43c6fe0fda"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_vocab_length=sum([len(i.split()) for i in train_sentences])\n",
        "max_vocab_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wxVfZ2Esuke",
        "outputId": "54d140c2-dd0f-4300-db1b-16319317ce6b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "798275"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets check the distribution of the sentence length\n",
        "import matplotlib.pyplot as plt\n",
        "sentence_lengths=[len(i.split()) for i in train_sentences]\n",
        "plt.hist(sentence_lengths,bins=7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "qamdoGUMxuuW",
        "outputId": "cd3920a5-2d46-41d5-8743-390148b6894c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2.4876e+04, 4.9100e+03, 3.6000e+02, 5.3000e+01, 8.0000e+00,\n",
              "        3.0000e+00, 2.0000e+00]),\n",
              " array([  1.        ,  37.71428571,  74.42857143, 111.14285714,\n",
              "        147.85714286, 184.57142857, 221.28571429, 258.        ]),\n",
              " <BarContainer object of 7 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How long of a sentence covers 95% of the lengths?\n",
        "import numpy as np\n",
        "output_sen_len=int(np.percentile(sentence_lengths,95))\n",
        "output_sen_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTVV1Vg5zZNn",
        "outputId": "3b883e43-e63c-49fb-9cf6-e88f10dc8abe"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Section 3.2 of the PubMed 200k RCT paper states the vocabulary size of the PubMed 20k dataset as 68,000. So we'll use that as our max_tokens parameter.\n",
        "\n"
      ],
      "metadata": {
        "id": "kBrSXxoT0t-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "max_length=55\n",
        "text_vectorizer=tf.keras.layers.TextVectorization(max_tokens=68000,\n",
        "                                                  output_sequence_length=max_length)\n"
      ],
      "metadata": {
        "id": "ihnywxgstETl"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "let's adapt it to the training data (let it read the training data and figure out what number should represent what word) and then test it out.\n",
        "\n"
      ],
      "metadata": {
        "id": "FQHk1UUf1IrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "Jl4-XdhV1Arx"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing our text vectorizer\n",
        "import random\n",
        "random_sentence=random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "        \\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKjY976v1NPM",
        "outputId": "4f8558c1-37d0-4713-b1b7-6a8327095c6a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "pre-specified secondary outcomes were changes in body weight , homa-ir , metabolic syndrome ( ms ) measures , leptin , and adiponectin .        \n",
            "\n",
            "Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 55), dtype=int64, numpy=\n",
              "array([[1313,  157,   76,    9,  154,    5,  256,  201, 2831,  728,  417,\n",
              "         964,  214, 6614,    3, 5218,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how many words are there in the vocabolary\n",
        "rct_20k_vocab=text_vectorizer.get_vocabulary()\n",
        "len(rct_20k_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aODiQd32NlV",
        "outputId": "d3fdb51b-5568-4be0-bd7c-d1b22570903e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25008"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the configuration of our text vectorizer\n",
        "text_vectorizer.get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb5acyPc2xoN",
        "outputId": "66e92dfa-20d6-46a0-de83-baad5f3bb5b1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'text_vectorization',\n",
              " 'trainable': True,\n",
              " 'dtype': {'module': 'keras',\n",
              "  'class_name': 'DTypePolicy',\n",
              "  'config': {'name': 'float32'},\n",
              "  'registered_name': None},\n",
              " 'max_tokens': 68000,\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'split': 'whitespace',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 55,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'sparse': False,\n",
              " 'ragged': False,\n",
              " 'vocabulary': None,\n",
              " 'idf_weights': None,\n",
              " 'encoding': 'utf-8',\n",
              " 'vocabulary_size': 25008}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(rct_20k_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahJJuW7sILgQ",
        "outputId": "b29aad52-2700-4c10-80c8-a305471d759c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25008"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings=tf.keras.layers.Embedding(input_dim=len(rct_20k_vocab), # length of vocabolary\n",
        "                                     output_dim=128, # Note: different embedding sizes result in drastically different numbers of parameters to train\n",
        "                                     mask_zero=True, # Use masking to handle variable sequences lengths\n",
        "                                     name=\"embedding\")\n"
      ],
      "metadata": {
        "id": "XrRTbkoxt6Dd"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing our text vectorizer\n",
        "import random\n",
        "random_sentence=random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "        \\n\\nVectorized version:\")\n",
        "print(text_vectorizer([random_sentence]))\n",
        "\n",
        "# testing our embedding\n",
        "print(\"########## After embeddings #########\")\n",
        "after_embeddings=embeddings(text_vectorizer([random_sentence]))\n",
        "after_embeddings,after_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGF211VuJY_n",
        "outputId": "23699fb1-7ee6-4b30-e6db-1789acb8a76c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "the mean calcium intake was @ @ mg/d and serum @ ( oh ) d was @ @ nmol/l at baseline .        \n",
            "\n",
            "Vectorized version:\n",
            "tf.Tensor(\n",
            "[[   2   53 1541  351   10 1298    3  244 1605  180   10 1949   16   50\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0]], shape=(1, 55), dtype=int64)\n",
            "########## After embeddings #########\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 55, 128), dtype=float32, numpy=\n",
              " array([[[ 0.02545626, -0.03685591,  0.04159356, ..., -0.04811586,\n",
              "          -0.01353885,  0.00658343],\n",
              "         [ 0.04927615, -0.00489407,  0.01184184, ..., -0.00254636,\n",
              "           0.04840914,  0.02432002],\n",
              "         [-0.00360794, -0.02582135, -0.00436939, ..., -0.03600902,\n",
              "          -0.0076965 ,  0.02379792],\n",
              "         ...,\n",
              "         [ 0.01722045,  0.00787631,  0.01054745, ..., -0.03359162,\n",
              "          -0.01852623, -0.00437423],\n",
              "         [ 0.01722045,  0.00787631,  0.01054745, ..., -0.03359162,\n",
              "          -0.01852623, -0.00437423],\n",
              "         [ 0.01722045,  0.00787631,  0.01054745, ..., -0.03359162,\n",
              "          -0.01852623, -0.00437423]]], dtype=float32)>,\n",
              " TensorShape([1, 55, 128]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To create a batched PrefetchDataset we can use the methods betch() and prefetch(), the parameter tf.data.AUTOTUNE will also allow Tensowflow to determine the optimal amount of compute to use to prepare datasets"
      ],
      "metadata": {
        "id": "16ta-YgTRQYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn our data into Tensorflow Datasets\n",
        "train_dataset=tf.data.Dataset.from_tensor_slices((train_sentences,train_labels_one_hot))\n",
        "test_dataset=tf.data.Dataset.from_tensor_slices((test_sentences,test_labels_one_hot))\n",
        "validation_dataset=tf.data.Dataset.from_tensor_slices((validation_sentences,validation_labels_one_hot))\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5IEOaowRzCW",
        "outputId": "c40241e9-7252-4a83-8880-25ee31fc84a8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take the tensor slices and turn them in to prefetch Batches\n",
        "train_dataset=train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "valid_dataset=validation_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset=test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "-iqWj23fS_ix"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1: Conv1D with token embeddings\n",
        "\n",
        "Input(text)-> Tokenize-> Embeddings -> Layers -> Output (label Probalility)"
      ],
      "metadata": {
        "id": "2_O--eXfUM_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a model with Functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs=layers.Input(shape=(1,),dtype=tf.string)\n",
        "x=text_vectorizer(inputs)\n",
        "x=embeddings(x)\n",
        "x=layers.Conv1D(filters=64,kernel_size=5,activation=\"relu\",padding=\"same\")(x)\n",
        "x=layers.GlobalAveragePooling1D()(x)\n",
        "outputs=layers.Dense(5,activation=\"sigmoid\")(x)\n",
        "model_1=tf.keras.Model(inputs,outputs,name=\"model_1_dense\")\n",
        "\n",
        "model_1.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "model_1.summary(\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "O-TLLO5Vp41g",
        "outputId": "dc711dc8-6d0d-4a8c-cb05-8fff134e2b5d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:938: UserWarning: Layer 'conv1d' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"model_1_dense\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_1_dense\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer (\u001b[38;5;33mInputLayer\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                           \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " text_vectorization               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              " (\u001b[38;5;33mTextVectorization\u001b[0m)                                                    \n",
              "\n",
              " embedding (\u001b[38;5;33mEmbedding\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m128\u001b[0m)             \u001b[38;5;34m3,201,024\u001b[0m \n",
              "\n",
              " conv1d (\u001b[38;5;33mConv1D\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m64\u001b[0m)                 \u001b[38;5;34m41,024\u001b[0m \n",
              "\n",
              " global_average_pooling1d         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              " (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)                                               \n",
              "\n",
              " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                         \u001b[38;5;34m325\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " text_vectorization               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)                                                    \n",
              "\n",
              " embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">3,201,024</span> \n",
              "\n",
              " conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">41,024</span> \n",
              "\n",
              " global_average_pooling1d         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)                                               \n",
              "\n",
              " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,242,373\u001b[0m (12.37 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,242,373</span> (12.37 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,242,373\u001b[0m (12.37 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,242,373</span> (12.37 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_1_history=model_1.fit(train_dataset,\n",
        "                            steps_per_epoch=int(0.1*len(train_dataset)), # Only fit 10% of the batches for the faster training time\n",
        "                            epochs=5,\n",
        "                            validation_data=valid_dataset,\n",
        "                            validation_steps=int(0.1*len(validation_dataset))\n",
        "                            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djLPbMO6S9ye",
        "outputId": "737c8dd5-3fc6-430c-b272-8ec759203e9f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m93/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3153 - loss: 1.5003"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 152ms/step - accuracy: 0.3165 - loss: 1.4992 - val_accuracy: 0.5094 - val_loss: 1.2997\n",
            "Epoch 2/5\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 103ms/step - accuracy: 0.5353 - loss: 1.1589 - val_accuracy: 0.6435 - val_loss: 0.8880\n",
            "Epoch 3/5\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6644 - loss: 0.8486 - val_accuracy: 0.6886 - val_loss: 0.7749\n",
            "Epoch 4/5\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 102ms/step - accuracy: 0.7003 - loss: 0.7619 - val_accuracy: 0.7189 - val_loss: 0.7371\n",
            "Epoch 5/5\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 103ms/step - accuracy: 0.7189 - loss: 0.7376 - val_accuracy: 0.7263 - val_loss: 0.7152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on whole validation dataset\n",
        "model_1.evaluate(valid_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktdHwsRGsnhD",
        "outputId": "c9e44744-a3c4-4d53-d368-3cbf4c08c9e3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m942/942\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.7238 - loss: 0.7186\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7152349948883057, 0.7262983322143555]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_pred_probs=model_1.predict(valid_dataset)\n",
        "model_1_pred_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoaOsIZycV-4",
        "outputId": "0c00f445-8d08-4842-d21b-cf7476131336"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m942/942\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.71651983, 0.6168426 , 0.38270244, 0.5510569 , 0.12180202],\n",
              "       [0.29386476, 0.20816576, 0.923359  , 0.42544508, 0.18328084],\n",
              "       [0.0403158 , 0.04556642, 0.99615204, 0.08564682, 0.8196124 ],\n",
              "       ...,\n",
              "       [0.09888558, 0.52676284, 0.5073256 , 0.05406569, 0.94992846],\n",
              "       [0.22792289, 0.4635591 , 0.6801538 , 0.1105135 , 0.8803234 ],\n",
              "       [0.13544461, 0.7096599 , 0.19257501, 0.14114399, 0.7740615 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results=calculate_results(y_true=validation_labels,y_pred=tf.argmax(model_1_pred_probs,axis=1))\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xJaocTRdlj8",
        "outputId": "3e53234f-2a84-4804-c117-76fbc13acce7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.62983242077318,\n",
              " 'precision': 0.7218496249355031,\n",
              " 'recall': 0.7262983242077319,\n",
              " 'f1': 0.7117471327481524}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2: Transfer Learning\n",
        "The model structure will look like:\n",
        "\n",
        "Inputs (string) -> Pretrained embeddings from TensorFlow Hub (Universal Sentence Encoder) -> Layers -> Output (prediction probabilities)\n",
        "\n",
        "\n",
        "There is lack of tokenization layer we've used in a previous model. This is because the Universal Sentence Encoder (USE) takes care of tokenization for us."
      ],
      "metadata": {
        "id": "X1w4GqUpeGRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the pretrained USE\n",
        "import tensorflow_hub as hub\n",
        "tf_hub_embeddings=hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                 trainable=False,\n",
        "                                 name=\"Universal_sentence_encoder\"\n",
        "\n",
        "                                )\n"
      ],
      "metadata": {
        "id": "bDGtPgVilO0T"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets test this pretrained embedding on a random sentence\n",
        "tf_hub_embeddings([random_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx7jf96_mjA_",
        "outputId": "da447938-a4eb-4b5b-e7e9-fa94cf052b18",
        "collapsed": true
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 512), dtype=float32, numpy=\n",
              "array([[ 0.00373557, -0.02115405, -0.00529531, -0.03322442, -0.02667352,\n",
              "         0.05342428,  0.00158975,  0.03706087,  0.00766055,  0.05812238,\n",
              "         0.01618551,  0.03709045, -0.04515425,  0.05695583, -0.08853193,\n",
              "        -0.03040999, -0.03325393,  0.08251486,  0.0075095 ,  0.00857904,\n",
              "        -0.07971729, -0.05969068, -0.03452222, -0.02334191, -0.05710603,\n",
              "        -0.04895816,  0.06105087, -0.01615   ,  0.01061311,  0.03219769,\n",
              "        -0.07630964,  0.0915279 ,  0.05765484,  0.02245149, -0.05602723,\n",
              "         0.02785195, -0.04784749, -0.00453227,  0.02803134,  0.00842119,\n",
              "         0.05788557,  0.04824861, -0.01584133,  0.07886814,  0.01423173,\n",
              "         0.02447024, -0.01721098,  0.04671942,  0.04072132, -0.00059816,\n",
              "         0.02058038, -0.02663067, -0.00467929, -0.03435716,  0.03270212,\n",
              "         0.03192814,  0.00227278,  0.02997621,  0.07735478, -0.06173814,\n",
              "         0.00198361, -0.01823302,  0.03894188, -0.00468802, -0.05675602,\n",
              "        -0.06879675, -0.00523246,  0.01758833,  0.0170957 , -0.01559928,\n",
              "         0.06485303,  0.02409052,  0.02847003,  0.0506143 ,  0.03093368,\n",
              "         0.052534  , -0.01031746,  0.02819802,  0.08330274,  0.07073273,\n",
              "        -0.0585676 ,  0.05694006,  0.00633008, -0.00257218,  0.06108596,\n",
              "         0.08254805,  0.03853931, -0.051292  ,  0.01319471, -0.01293296,\n",
              "        -0.01891804,  0.01051656,  0.04336157,  0.04367845, -0.0883877 ,\n",
              "         0.02299978, -0.0554406 , -0.08237276,  0.01304942, -0.02378159,\n",
              "        -0.02270221,  0.08355431,  0.04422549, -0.03112617,  0.01774026,\n",
              "        -0.08847406, -0.0426812 ,  0.0392544 ,  0.08151979,  0.06054778,\n",
              "         0.04723495, -0.03893843, -0.02300114, -0.06938557, -0.03011587,\n",
              "        -0.04442262,  0.0670464 ,  0.02053528,  0.00934389, -0.07368566,\n",
              "        -0.05147255,  0.06430732, -0.07915695,  0.01339164,  0.01457384,\n",
              "         0.00833036, -0.02506201,  0.05084277, -0.00818453,  0.0526146 ,\n",
              "         0.02966136,  0.09549238,  0.05966272,  0.06335138, -0.01036402,\n",
              "         0.00843232,  0.02580667, -0.04962847, -0.04706787,  0.07336693,\n",
              "        -0.03557947,  0.06090955,  0.00825271, -0.02457422,  0.04219036,\n",
              "         0.06392317, -0.03612676, -0.05705781, -0.01583879, -0.01710964,\n",
              "         0.00389348,  0.03358758, -0.06961   , -0.04050218,  0.09520859,\n",
              "         0.05041348,  0.02915942, -0.01979455, -0.02585808,  0.00630886,\n",
              "         0.03335285, -0.03252001, -0.05134553, -0.02806073,  0.07418495,\n",
              "        -0.04548791, -0.02865497, -0.06438702,  0.02989652, -0.0367518 ,\n",
              "        -0.0430104 ,  0.00815121,  0.045332  , -0.04195955,  0.01067092,\n",
              "         0.05629903, -0.06816851,  0.02310505,  0.05042821,  0.03081476,\n",
              "         0.00753832,  0.03914426,  0.06874138,  0.03800948,  0.03245867,\n",
              "        -0.01553308,  0.06325058, -0.00983473, -0.00599253, -0.02837731,\n",
              "        -0.00168188, -0.04562756,  0.0335437 , -0.02172686,  0.00400918,\n",
              "         0.07060432,  0.04215373, -0.07311474,  0.05049856,  0.04538926,\n",
              "         0.04227717,  0.03492581, -0.0908335 ,  0.03871823, -0.03933382,\n",
              "        -0.04019447,  0.07747833,  0.02801657, -0.03027627, -0.00074884,\n",
              "         0.05607945,  0.00043131, -0.07559984, -0.01318384, -0.01014098,\n",
              "         0.01656365,  0.08793397, -0.00808949, -0.0318443 , -0.05949036,\n",
              "         0.02964808, -0.00688603, -0.04328547, -0.03069627,  0.06042946,\n",
              "        -0.0085432 , -0.04568934,  0.09487292, -0.06872755, -0.03737974,\n",
              "         0.00433167,  0.00948476, -0.03173412, -0.08886074, -0.02264464,\n",
              "         0.00111959,  0.08231992,  0.01796716, -0.00228972,  0.04749057,\n",
              "         0.06150558, -0.02874923,  0.0634391 , -0.00359443,  0.0186348 ,\n",
              "        -0.04486589, -0.00531229,  0.00595147, -0.01674475, -0.0706628 ,\n",
              "        -0.02238681,  0.0237185 , -0.01447381,  0.0619095 ,  0.07036623,\n",
              "        -0.08282835, -0.03033346, -0.00154981,  0.03602047,  0.01285437,\n",
              "        -0.0312654 ,  0.05342771, -0.07207805, -0.04688202, -0.03859238,\n",
              "        -0.02521363, -0.0384224 ,  0.02991301, -0.03014322,  0.01210818,\n",
              "        -0.05719772,  0.0507696 ,  0.06517451, -0.0733262 , -0.02306286,\n",
              "        -0.02847391,  0.00613469,  0.02405291, -0.03486245, -0.00125957,\n",
              "        -0.01978535,  0.03440057,  0.04602567, -0.02164526, -0.02281567,\n",
              "        -0.03507071, -0.05180467,  0.06618439, -0.0470757 ,  0.00138487,\n",
              "        -0.02160648, -0.03184063,  0.01436501,  0.00529416, -0.06176079,\n",
              "        -0.02258963, -0.00379088, -0.01635586, -0.06473789, -0.02430362,\n",
              "         0.06283998, -0.00292317, -0.01620567, -0.06930707, -0.06402266,\n",
              "        -0.06600691, -0.04729217, -0.06413705,  0.0323182 , -0.00309645,\n",
              "        -0.05484594,  0.05021942,  0.06350333, -0.02695203,  0.07244691,\n",
              "         0.04684958,  0.00101104, -0.05830442,  0.01548835,  0.03393662,\n",
              "         0.00771746, -0.06343476,  0.05744442,  0.08077145, -0.0026736 ,\n",
              "        -0.0155201 ,  0.0483615 , -0.0504407 , -0.06664361,  0.00332124,\n",
              "         0.03427366, -0.04620738,  0.06714674,  0.00850077,  0.0295848 ,\n",
              "         0.03805602, -0.00075169,  0.00434715, -0.04834165,  0.05544075,\n",
              "        -0.04207542, -0.03423515,  0.02690757, -0.00507977, -0.03293883,\n",
              "        -0.09875547,  0.05818446,  0.05176456, -0.03007428, -0.0240551 ,\n",
              "        -0.05668972,  0.02747411,  0.02803479, -0.02577766,  0.03195634,\n",
              "        -0.03623852, -0.09067081, -0.0609621 ,  0.01168569, -0.04468662,\n",
              "        -0.00959089, -0.06814107, -0.03481328, -0.0076591 ,  0.02981421,\n",
              "         0.05118931, -0.00815642,  0.04309649,  0.05437362,  0.01765027,\n",
              "         0.01359235,  0.03082403,  0.02431278, -0.09800774,  0.0257082 ,\n",
              "        -0.01842755, -0.05499825, -0.02462698, -0.02655458, -0.01478258,\n",
              "        -0.05972788, -0.02841521, -0.00390948,  0.04187231,  0.02591904,\n",
              "         0.01649895, -0.04002263, -0.0066745 , -0.03388069, -0.02805224,\n",
              "         0.05369258,  0.03909152, -0.02329099, -0.0768946 ,  0.06300492,\n",
              "        -0.01418187,  0.01190116, -0.05191955,  0.02206754, -0.09923513,\n",
              "        -0.00625591,  0.01447558,  0.04120876, -0.07081983,  0.05961569,\n",
              "        -0.05711832,  0.06836741,  0.01717142,  0.03166426,  0.04374728,\n",
              "        -0.06722359,  0.00531962,  0.01712658,  0.02579782,  0.07396819,\n",
              "         0.00549988,  0.00580737,  0.05334656, -0.05843872,  0.03062776,\n",
              "        -0.02584597, -0.05967572, -0.05122339,  0.01161565,  0.01142638,\n",
              "        -0.03570399,  0.06482848,  0.03533646,  0.02846691, -0.03142692,\n",
              "        -0.01365546, -0.05024893,  0.01026171, -0.0330273 ,  0.06709656,\n",
              "         0.04194584,  0.0617616 ,  0.02843948,  0.02754734,  0.00509745,\n",
              "        -0.00176446, -0.04074796, -0.03063777,  0.00014526,  0.0304081 ,\n",
              "        -0.03790873, -0.05582272,  0.01444073, -0.02310306,  0.0489263 ,\n",
              "        -0.07271741,  0.00228562,  0.02631672,  0.04089621, -0.07528417,\n",
              "        -0.04500497, -0.04072798, -0.04542286, -0.00592583,  0.04028194,\n",
              "        -0.0192474 , -0.03243548, -0.03046097, -0.01388606,  0.04564492,\n",
              "        -0.08221482,  0.04597414, -0.02033175, -0.05523729, -0.01530433,\n",
              "        -0.07983784, -0.01919425,  0.02827399,  0.08435658,  0.04754863,\n",
              "         0.05188483, -0.01488889, -0.04801926, -0.01827505, -0.00253419,\n",
              "        -0.01713509,  0.04936332, -0.02964338,  0.03131187, -0.03653899,\n",
              "         0.05316566, -0.016429  , -0.06800125, -0.03362533, -0.04755542,\n",
              "         0.02772982, -0.06253283,  0.0153739 , -0.06709301,  0.03778155,\n",
              "         0.00485733,  0.00625855,  0.03153265,  0.04125089, -0.04065891,\n",
              "        -0.07224037, -0.05949442,  0.05790999,  0.06868266,  0.0950868 ,\n",
              "        -0.04017383, -0.04191352, -0.0138048 , -0.01286227,  0.01151902,\n",
              "        -0.00344663, -0.03480618]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# length of embedding\n",
        "len(tf_hub_embeddings([random_sentence])[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMH1mIbwmxwZ",
        "outputId": "d061adc7-dc28-4d7d-e5b3-d5941ff4fc0c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs = layers.Input(shape=[], dtype=tf.string)\n",
        "# pretrained_embedding = tf_hub_embeddings(inputs) # tokenize text and create embedding\n",
        "# x = layers.Dense(128, activation=\"relu\")(pretrained_embedding) # add a fully connected layer on top of the embedding\n",
        "# # Note: you could add more layers here if you wanted to\n",
        "# outputs = layers.Dense(5, activation=\"softmax\")(x) # create the output layer\n",
        "# model_2 = tf.keras.Model(inputs=inputs,\n",
        "#                         outputs=outputs)\n",
        "\n",
        "# # Compile the model\n",
        "# model_2.compile(loss=\"categorical_crossentropy\",\n",
        "#                 optimizer=tf.keras.optimizers.Adam(),\n",
        "#                 metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "em37RLHTsMWN"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building and fitting an NLP feature extraction model from TF Hub\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "# Wrap USE inside a custom Keras Layer\n",
        "class USEEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, trainable=False, **kwargs):\n",
        "        super(USEEmbedding, self).__init__(trainable=trainable, **kwargs)\n",
        "        self.use = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.use(inputs)\n",
        "\n",
        "# Keras Input (1D: batch of strings)\n",
        "input_text = tf.keras.Input(shape=(), dtype=tf.string, name=\"input_text\")\n",
        "\n",
        "# Embed using our wrapped USE Layer\n",
        "embedding = USEEmbedding()(input_text)\n",
        "\n",
        "# Add classification layers\n",
        "x = layers.Dense(128, activation=\"relu\")(embedding)\n",
        "output = layers.Dense(num_classes, activation=\"sigmoid\")(x)\n",
        "\n",
        "# Build model\n",
        "model_2 = Model(inputs=input_text, outputs=output)\n",
        "model_2.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Show model summary\n",
        "model_2.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "ViCs-sMnnX0J",
        "outputId": "4c99e910-6ec0-4cd5-aa20-5854fae0a43d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_text (\u001b[38;5;33mInputLayer\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m)                              \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " use_embedding (\u001b[38;5;33mUSEEmbedding\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m65,664\u001b[0m \n",
              "\n",
              " dense_2 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                         \u001b[38;5;34m645\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " input_text (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " use_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">USEEmbedding</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> \n",
              "\n",
              " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m66,309\u001b[0m (259.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,309</span> (259.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m66,309\u001b[0m (259.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,309</span> (259.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.fit(train_dataset,\n",
        "            steps_per_epoch=int(0.1*len(train_dataset)),\n",
        "            epochs=5,\n",
        "            validation_data=valid_dataset,\n",
        "            validation_steps=int(0.1*len(valid_dataset))\n",
        "            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQguSUK-o9YI",
        "outputId": "f351ddae-423e-4edf-c321-b8af6592f6b6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.4021 - loss: 0.5708 - val_accuracy: 0.5645 - val_loss: 0.3832\n",
            "Epoch 2/5\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.5785 - loss: 0.3645 - val_accuracy: 0.6370 - val_loss: 0.3240\n",
            "Epoch 3/5\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.6447 - loss: 0.3184 - val_accuracy: 0.6669 - val_loss: 0.3055\n",
            "Epoch 4/5\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.6714 - loss: 0.3015 - val_accuracy: 0.6725 - val_loss: 0.2961\n",
            "Epoch 5/5\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.6567 - loss: 0.3048 - val_accuracy: 0.6918 - val_loss: 0.2883\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a833d463510>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "model_2_preds=model_2.predict(valid_dataset)\n",
        "model_2_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7LbYLRVthi8",
        "outputId": "f747ff12-c6d0-443e-e7fe-456187929512"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m942/942\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4342206 , 0.16233046, 0.17977983, 0.25821105, 0.02311125],\n",
              "       [0.15749921, 0.09452142, 0.4939919 , 0.21139203, 0.01152465],\n",
              "       [0.00746541, 0.01450854, 0.9379996 , 0.00637806, 0.11353775],\n",
              "       ...,\n",
              "       [0.00343746, 0.02979523, 0.03468885, 0.00094049, 0.93072546],\n",
              "       [0.0284382 , 0.07623503, 0.1172111 , 0.01428585, 0.7865331 ],\n",
              "       [0.01549106, 0.3150947 , 0.3638515 , 0.02622725, 0.1262401 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results=calculate_results(validation_labels,tf.argmax(model_2_preds,axis=1))\n",
        "model_2_results"
      ],
      "metadata": {
        "id": "Hw1XSxQjuhRE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbfc6353-1c58-434f-be91-76990407bcef"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 67.96747967479675,\n",
              " 'precision': 0.6741576759428011,\n",
              " 'recall': 0.6796747967479675,\n",
              " 'f1': 0.6680531689215379}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 3: Conv1D with character embeddings\n",
        "The difference between a character and token embedding is that the character embedding is created using sequences split into characters (e.g. hello -> [h, e, l, l, o]) where as a token embedding is created on sequences split into tokens. Token level embeddings split sequences into tokens (words) and embeddings each of them, character embeddings split sequences into characters and creates a feature vector for each."
      ],
      "metadata": {
        "id": "7rJl1_Fq2rkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make function to split senntences into characters\n",
        "def split_sentences(text):\n",
        "  return \" \".join(list(text))"
      ],
      "metadata": {
        "id": "QNDtnLCE80Om"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing functioon\n",
        "split_sentences(random_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "LwoAAcFO9YwP",
        "outputId": "dba77604-5883-41e7-b460-a6f39c1d02ea"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'t h e   m e a n   c a l c i u m   i n t a k e   w a s   @   @   m g / d   a n d   s e r u m   @   (   o h   )   d   w a s   @   @   n m o l / l   a t   b a s e l i n e   .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets  create character level dataset by splitting our dataset into characters\n",
        "train_chars=[split_sentences(s) for s in train_sentences]\n",
        "val_chars=[split_sentences(s) for s in validation_sentences]\n",
        "test_chars=[split_sentences(s) for s in test_sentences]\n",
        "test_chars[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "Irbg2c3A9jd7",
        "outputId": "3035ec72-08c9-4ef8-990d-35e99748ae64"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets check the average character length\n",
        "char_length=[len(s) for s in train_sentences]\n",
        "mean_chars=np.mean(char_length)\n",
        "mean_chars"
      ],
      "metadata": {
        "id": "kRGFGAKX-4em",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "941ac676-3157-4c21-d685-5d4698a05e44"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(149.19111611280286)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(char_length,bins=7\n",
        "         )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "jzRD5GMHkGGQ",
        "outputId": "a8d6713f-e86e-4b23-8480-f1bd70a557f7"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.8576e+04, 1.0579e+04, 9.2800e+02, 1.0600e+02, 1.6000e+01,\n",
              "        5.0000e+00, 2.0000e+00]),\n",
              " array([   2.        ,  157.14285714,  312.28571429,  467.42857143,\n",
              "         622.57142857,  777.71428571,  932.85714286, 1088.        ]),\n",
              " <BarContainer object of 7 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets find the 95% percentile of our character length\n",
        "output_char_length=int(np.percentile(char_length,95))\n",
        "output_char_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-YwWrRbkKSu",
        "outputId": "0cedf101-a487-40e9-bd4e-88d62add48ff"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "290"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we'll set the max_tokens ( the total number of different character in our sentences) to 28, in other words, 26 letters of the alphabet + space +OOV (Out of vocabolary or unknown) tokens.\n"
      ],
      "metadata": {
        "id": "rRLUTRKPlwb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get all keyboard character for character level embeddings\n",
        "import string\n",
        "alphabet = string.ascii_lowercase+string.digits+string.punctuation\n",
        "alphabet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "m8O3dukFlI3a",
        "outputId": "ca23719f-2883-45b9-daa1-01710922511a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create  char level token vectorizer instance\n",
        "NUM_CHAR_TOKENS=len(alphabet)+2 # this means number of characters in alphabet + space + OOV token\n",
        "char_vectorizer=tf.keras.layers.TextVectorization(max_tokens=NUM_CHAR_TOKENS,\n",
        "                                  output_sequence_length=output_char_length,\n",
        "                                  standardize=\"lower_and_strip_punctuation\",\n",
        "                                  name=\"char_vectorizer\")\n",
        "# adapt char vectorizer to training characters\n",
        "char_vectorizer.adapt(train_chars)"
      ],
      "metadata": {
        "id": "UxzFBPXMnLCc"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets check the character vocabolary characterstics\n",
        "char_vocab= char_vectorizer.get_vocabulary()\n",
        "print(f\"Number of character in vocabolary {len(char_vocab)}\")\n",
        "print(f\" 5 most common characters { char_vocab[:5]}\")\n",
        "print(f\" 5 least common characters { char_vocab[:-5]}\")"
      ],
      "metadata": {
        "id": "1S-SDXHZo3Z4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e803a33c-8d4e-464d-bf8b-8262c6661174"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of character in vocabolary 28\n",
            " 5 most common characters ['', '[UNK]', np.str_('e'), np.str_('t'), np.str_('i')]\n",
            " 5 least common characters ['', '[UNK]', np.str_('e'), np.str_('t'), np.str_('i'), np.str_('a'), np.str_('n'), np.str_('o'), np.str_('r'), np.str_('s'), np.str_('d'), np.str_('c'), np.str_('l'), np.str_('h'), np.str_('p'), np.str_('m'), np.str_('u'), np.str_('f'), np.str_('g'), np.str_('y'), np.str_('w'), np.str_('v'), np.str_('b')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets test out char vectorizer\n",
        "random_chars=random.choice(train_chars)\n",
        "print(f\"Random sentence : {random_chars}\")\n",
        "print(f\"vectorized sentence : {char_vectorizer([random_chars])}\")\n",
        "print(f\"length: {len(char_vectorizer([random_chars])[0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dA2Fsh-XXqjV",
        "outputId": "8ae1493e-b15d-415c-e03e-e0a94a4fd830"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random sentence : c l i n i c a l t r i a l s . g o v   :   n c t @   .\n",
            "vectorized sentence : [[11 12  4  6  4 11  5 12  3  8  4  5 12  9 18  7 21  6 11  3  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0]]\n",
            "length: 290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The input dimension (input_dim) will be equal to the number of different characters in our char_vocab (28). And since we're following the structure of the model in Figure 1 of Neural Networks for [Joint Sentence Classification in Medical Paper Abstracts](https://arxiv.org/pdf/1612.05251), the output dimension of the character embedding (output_dim) will be 25."
      ],
      "metadata": {
        "id": "YbKjCT5Ufb3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a character embedding layer\n",
        "print(random_chars)\n",
        "char_embedding=layers.Embedding(input_dim=NUM_CHAR_TOKENS,\n",
        "                                output_dim=25,\n",
        "                                mask_zero=False,\n",
        "                                name=\"char_embedding\")\n",
        "\n",
        "char_embedding_output=char_embedding(char_vectorizer([random_chars]))\n",
        "print(char_embedding_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhps2tKjZErA",
        "outputId": "35217fc6-11e4-4275-c92a-e74ba137e61b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c l i n i c a l t r i a l s . g o v   :   n c t @   .\n",
            "tf.Tensor(\n",
            "[[[-0.00728596  0.02159294  0.02164084 ... -0.00260261  0.03746629\n",
            "   -0.02815504]\n",
            "  [-0.01772862  0.04762429 -0.01831704 ... -0.02284648 -0.02408074\n",
            "   -0.02810076]\n",
            "  [-0.00147054  0.00200035 -0.01273507 ...  0.00719695 -0.04901464\n",
            "    0.00550497]\n",
            "  ...\n",
            "  [ 0.02885893 -0.0366493   0.0150923  ...  0.01884839 -0.01659147\n",
            "    0.00870001]\n",
            "  [ 0.02885893 -0.0366493   0.0150923  ...  0.01884839 -0.01659147\n",
            "    0.00870001]\n",
            "  [ 0.02885893 -0.0366493   0.0150923  ...  0.01884839 -0.01659147\n",
            "    0.00870001]]], shape=(1, 290, 25), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets make our model\n",
        "\n",
        "Input (character-level text) -> Tokenize -> Embedding -> Layers (Conv1D, GlobalMaxPool1D) -> Output (label probability)"
      ],
      "metadata": {
        "id": "zVTf4mvPlX6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=layers.Input(shape=(1,),dtype=\"string\")\n",
        "char_vectors=char_vectorizer(inputs)\n",
        "embedding=char_embedding(char_vectors)\n",
        "x=layers.Conv1D(64,kernel_size=5,padding=\"same\", activation=\"relu\")(embedding)\n",
        "x=layers.GlobalMaxPool1D()(x)\n",
        "outputs=layers.Dense(num_classes,activation=\"softmax\")(x)\n",
        "model_3=tf.keras.Model(inputs,outputs,name=\"model_3_char_embedding\")\n",
        "\n",
        "model_3.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy']\n",
        "                )"
      ],
      "metadata": {
        "id": "nIDsyPkNhPHE"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "MHG-14Fun51S",
        "outputId": "a4687a46-1f84-4d74-d2f7-59bf9951fad7"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"model_3_char_embedding\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_3_char_embedding\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                           \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " char_vectorizer                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m290\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
              " (\u001b[38;5;33mTextVectorization\u001b[0m)                                                    \n",
              "\n",
              " char_embedding (\u001b[38;5;33mEmbedding\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m290\u001b[0m, \u001b[38;5;34m25\u001b[0m)                 \u001b[38;5;34m1,750\u001b[0m \n",
              "\n",
              " conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m290\u001b[0m, \u001b[38;5;34m64\u001b[0m)                 \u001b[38;5;34m8,064\u001b[0m \n",
              "\n",
              " global_max_pooling1d             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              " (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)                                                   \n",
              "\n",
              " dense_3 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                         \u001b[38;5;34m325\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " char_vectorizer                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">290</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)                                                    \n",
              "\n",
              " char_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">290</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">1,750</span> \n",
              "\n",
              " conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">290</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">8,064</span> \n",
              "\n",
              " global_max_pooling1d             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)                                                   \n",
              "\n",
              " dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,139\u001b[0m (39.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,139</span> (39.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,139\u001b[0m (39.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,139</span> (39.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before fitting our model, lets create a char-level batched PrefetchedDataset"
      ],
      "metadata": {
        "id": "UwfxVe47oFUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_char_dataset=tf.data.Dataset.from_tensor_slices((train_chars,train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_char_dataset=tf.data.Dataset.from_tensor_slices((val_chars,validation_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "xkG8eBWgn8bg"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_char_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UWDtFlQpbGS",
        "outputId": "4551e91e-3646-43f6-dd52-23dd7a75fdc2"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just line our token-level sequence model, to save time with our experiments, we'll fit our model in 10% of batches"
      ],
      "metadata": {
        "id": "7S5YUlFMpjid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_history=model_3.fit(train_char_dataset,\n",
        "                            steps_per_epoch=int(0.1*len(train_char_dataset)),\n",
        "                            epochs=5,\n",
        "                            validation_data=val_char_dataset,\n",
        "                            validation_steps=int(0.1*len(val_char_dataset)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhtE0vx8peGM",
        "outputId": "c65b0b70-a6f0-4284-d9cc-0095307aeaf7"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.3095 - loss: 1.5405 - val_accuracy: 0.4578 - val_loss: 1.4114\n",
            "Epoch 2/5\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.4232 - loss: 1.4023 - val_accuracy: 0.4545 - val_loss: 1.3110\n",
            "Epoch 3/5\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.4651 - loss: 1.2970 - val_accuracy: 0.5156 - val_loss: 1.1732\n",
            "Epoch 4/5\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.5201 - loss: 1.1819 - val_accuracy: 0.5406 - val_loss: 1.0899\n",
            "Epoch 5/5\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.5350 - loss: 1.1276 - val_accuracy: 0.5718 - val_loss: 1.0492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate on whole validation dataset\n",
        "model_3.evaluate(val_char_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LA1L48AYrXqs",
        "outputId": "18f8b80f-8f4e-48be-b821-5930ce6db59a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m942/942\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5594 - loss: 1.0776\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0799273252487183, 0.5580886006355286]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "model_3_pred=model_3.predict(val_char_dataset)\n",
        "model_3_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5_Bu6bdqf2M",
        "outputId": "08023cb7-f859-48ce-a1c7-832b3bce2521"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m942/942\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.3046122 , 0.19122885, 0.18838374, 0.20194831, 0.11382685],\n",
              "       [0.14258374, 0.28708333, 0.23931105, 0.14769006, 0.18333186],\n",
              "       [0.01807877, 0.02535191, 0.4671553 , 0.01169424, 0.47771984],\n",
              "       ...,\n",
              "       [0.01022409, 0.0331662 , 0.11333869, 0.01064458, 0.8326264 ],\n",
              "       [0.03354989, 0.06762888, 0.3336622 , 0.01700521, 0.5481539 ],\n",
              "       [0.1243641 , 0.29970136, 0.3218982 , 0.11500224, 0.13903406]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert predictions to classes\n",
        "model_3_pred_classes=tf.argmax(model_3_pred,axis=1)\n",
        "model_3_pred_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEeyAhLbq7f_",
        "outputId": "452537b1-cd51-45f0-c25a-3c2bd8099d8e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30135,), dtype=int64, numpy=array([0, 1, 4, ..., 4, 4, 2])>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_results=calculate_results(validation_labels,model_3_pred_classes)\n",
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZnvp2jdtY0m",
        "outputId": "a2cebe68-71bd-4756-eafd-6727ea802090"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 55.808860129417624,\n",
              " 'precision': 0.5748982281172661,\n",
              " 'recall': 0.5580886012941763,\n",
              " 'f1': 0.5198768492464168}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 4: combining pretrained token embeddings and char embeddings (hybrid embedding)\n",
        "\n",
        "To start replicating (or getting close to replicating) the model in Figure 1, we're going to go through the following steps:\n",
        "\n",
        "Create a token-level model (similar to model_1)\n",
        "Create a character-level model (similar to model_3 with a slight modification to reflect the paper)\n",
        "Combine (using layers.Concatenate) the outputs of 1 and 2\n",
        "Build a series of output layers on top of 3 similar to Figure 1 and section 4.2 of Neural Networks for Joint Sentence Classification in Medical Paper Abstracts\n",
        "Construct a model which takes token and character-level sequences as input and produces sequence label probabilities as output"
      ],
      "metadata": {
        "id": "aslSAESftxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # 1. Setup token input model\n",
        "# token_inputs=layers.Input(shape=[],dtype=\"string\",name=\"token_input\")\n",
        "# # token_vectors=text_vectorizer(token_inputs)\n",
        "# # token_embedding=embeddings(token_vectors)\n",
        "# token_embedding=tf_hub_embeddings(token_inputs)\n",
        "# token_outputs=layers.Dense(128,activation=\"relu\")(token_embedding)\n",
        "# token_model=tf.keras.Model(token_inputs,token_outputs)\n",
        "\n",
        "# #2. setup char input model\n",
        "# char_inputs=layers.Input(shape=(1,),dtype=\"string\",name=\"char_input\")\n",
        "# char_vectors=char_vectorizer(char_inputs)\n",
        "# char_embedding=char_embedding(char_vectors)\n",
        "# char_bi_lstm=layers.Bidirectional(layers.LSTM(64))(char_embedding)\n",
        "# char_model=tf.keras.Model(char_inputs,char_bi_lstm)\n",
        "\n",
        "# # 3. concatenate token and char model 1 and 2\n",
        "# token_char_concat=layers.Concatenate(name=\"concatenated_model\")([token_model.output, char_model.output])\n",
        "\n",
        "# # 4. create output layers. addition of dropout discussed in 4.2 of https://arxiv.org/pdf/1612.05251.pdf\n",
        "# combined_dropout=layers.Dropout(0.5)(token_char_concat)\n",
        "# combined_debse=layers.Dense(200, activation=\"relu\")(combined_dropout)\n",
        "# final_dropout=layers.Dropout(0.5)(combined_dense)\n",
        "# output_layer=layers.Dense(5,activation=\"softmax\")(final_fropout)\n",
        "\n",
        "# #5. construct model with char and token inputs\n",
        "# model_4=tf.keras.Model(inputs=[token_model.input,char_model.input],\n",
        "#                        outputs=output_layer,\n",
        "#                        name=\"model_4_hybrid\")\n"
      ],
      "metadata": {
        "id": "YHH2XluyuE_q"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text  # Required for USE\n",
        "\n",
        "# Step 1: Wrap the USE model in a Keras-compatible layer\n",
        "class USEWrapper(layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(USEWrapper, self).__init__(**kwargs)\n",
        "        self.use = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.use(inputs)\n",
        "\n",
        "# Step 2: Token-level input model\n",
        "token_inputs = layers.Input(shape=(), dtype=tf.string, name=\"token_input\")\n",
        "token_embedding = USEWrapper(name=\"use_layer\")(token_inputs)\n",
        "token_outputs = layers.Dense(128, activation=\"relu\")(token_embedding)\n",
        "token_model = keras.Model(inputs=token_inputs, outputs=token_outputs)\n",
        "\n",
        "char_inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"char_input\")\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embedded = char_embedding(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(25))(char_embedded)\n",
        "char_model = keras.Model(inputs=char_inputs, outputs=char_bi_lstm)\n",
        "\n",
        "# Step 4: Concatenate token and char outputs\n",
        "token_char_concat = layers.Concatenate(name=\"concatenated\")(\n",
        "    [token_model.output, char_model.output]\n",
        ")\n",
        "\n",
        "# Step 5: Output layers\n",
        "x = layers.Dropout(0.5)(token_char_concat)\n",
        "x = layers.Dense(200, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "output_layer = layers.Dense(5, activation=\"softmax\")(x)  # Adjust number of classes\n",
        "\n",
        "# Step 6: Full model\n",
        "model_4 = keras.Model(\n",
        "    inputs=[token_model.input, char_model.input],\n",
        "    outputs=output_layer,\n",
        "    name=\"model_4_hybrid\"\n",
        ")\n",
        "\n",
        "# Compile model\n",
        "model_4.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Optional: Print model summary\n",
        "model_4.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "vFm_VUqT54vx",
        "outputId": "c601c6dd-aef1-4bd1-b94e-fb5f18093e7a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"model_4_hybrid\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_4_hybrid\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " char_input           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " token_input          (\u001b[38;5;45mNone\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " char_vectorizer      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m290\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  char_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              " (\u001b[38;5;33mTextVectorization\u001b[0m)                                                   \n",
              "\n",
              " use_layer            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  token_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mUSEWrapper\u001b[0m)                                                          \n",
              "\n",
              " char_embedding       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m290\u001b[0m, \u001b[38;5;34m25\u001b[0m)         \u001b[38;5;34m1,750\u001b[0m  char_vectorizer[\u001b[38;5;34m\u001b[0m \n",
              " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
              "\n",
              " dense_4 (\u001b[38;5;33mDense\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m65,664\u001b[0m  use_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " bidirectional        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             \u001b[38;5;34m10,200\u001b[0m  char_embedding[\u001b[38;5;34m1\u001b[0m \n",
              " (\u001b[38;5;33mBidirectional\u001b[0m)                                                       \n",
              "\n",
              " concatenated         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m178\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    \n",
              " (\u001b[38;5;33mConcatenate\u001b[0m)                                       bidirectional[\u001b[38;5;34m0\u001b[0m] \n",
              "\n",
              " dropout (\u001b[38;5;33mDropout\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m178\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  concatenated[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
              "\n",
              " dense_5 (\u001b[38;5;33mDense\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            \u001b[38;5;34m35,800\u001b[0m  dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
              "\n",
              " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
              "\n",
              " dense_6 (\u001b[38;5;33mDense\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)               \u001b[38;5;34m1,005\u001b[0m  dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
              "\n",
              " char_input           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " token_input          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " char_vectorizer      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">290</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  char_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)                                                   \n",
              "\n",
              " use_layer            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  token_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">USEWrapper</span>)                                                          \n",
              "\n",
              " char_embedding       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">290</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,750</span>  char_vectorizer[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
              "\n",
              " dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span>  use_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " bidirectional        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">10,200</span>  char_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                                                       \n",
              "\n",
              " concatenated         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">178</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "\n",
              " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">178</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  concatenated[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "\n",
              " dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">35,800</span>  dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
              "\n",
              " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
              "\n",
              " dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">1,005</span>  dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m114,419\u001b[0m (446.95 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">114,419</span> (446.95 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m114,419\u001b[0m (446.95 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">114,419</span> (446.95 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zMCFOdHT6Bum"
      },
      "execution_count": 74,
      "outputs": []
    }
  ]
}